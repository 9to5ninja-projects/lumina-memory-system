{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HRR Spatial Environment Fine-Tuning\n",
    "\n",
    "**Objective**: Fine-tune our HRR-based spatial environment for optimal unit relationships and behavior.\n",
    "\n",
    "This notebook focuses on:\n",
    "- Optimizing HRR dimensionality for spatial positioning\n",
    "- Fine-tuning environmental behavior formulas\n",
    "- Calibrating unit relationship dynamics\n",
    "- Validating spatial memory performance\n",
    "- Testing consciousness battery integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.getcwd(), '..', 'src'))\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import time\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Import our spatial environment components\n",
    "try:\n",
    "    from lumina_memory.spatial_environment import (\n",
    "        SpatialEnvironment, SpatialUnit, EnvironmentalBehavior,\n",
    "        AttributeSpace, UnitRelationship\n",
    "    )\n",
    "    from lumina_memory.hrr import HRROperations\n",
    "    from lumina_memory.spatial_memory_system import SpatialMemorySystem\n",
    "    print(\"‚úÖ Spatial environment modules loaded successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Import error: {e}\")\n",
    "    print(\"Creating mock implementations for development...\")\n",
    "    \n",
    "    # Mock implementations for development\n",
    "    class MockSpatialEnvironment:\n",
    "        def __init__(self, dimensions=128):\n",
    "            self.dimensions = dimensions\n",
    "            self.units = []\n",
    "            \n",
    "        def add_unit(self, unit_id, attributes):\n",
    "            self.units.append({'id': unit_id, 'attributes': attributes})\n",
    "            \n",
    "        def get_relationships(self):\n",
    "            return [(u1['id'], u2['id'], np.random.random()) \n",
    "                   for u1 in self.units for u2 in self.units if u1 != u2]\n",
    "    \n",
    "    SpatialEnvironment = MockSpatialEnvironment\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üßÆ HRR Spatial Environment Tuning Framework Loaded\")\n",
    "print(\"Ready for fine-tuning unit relationships and behavior!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. HRR Dimensionality Optimization\n",
    "\n",
    "**Goal**: Find the optimal HRR dimensionality for spatial positioning that balances:\n",
    "- Memory efficiency\n",
    "- Relationship accuracy\n",
    "- Computational performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DimensionalityTestResult:\n",
    "    dimensions: int\n",
    "    accuracy: float\n",
    "    memory_mb: float\n",
    "    operations_per_sec: float\n",
    "    relationship_precision: float\n",
    "\n",
    "def test_hrr_dimensionality(dimensions_list: List[int], num_units: int = 20) -> List[DimensionalityTestResult]:\n",
    "    \"\"\"Test different HRR dimensionalities for spatial positioning.\"\"\"\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for dims in dimensions_list:\n",
    "        print(f\"Testing {dims}D HRR...\")\n",
    "        \n",
    "        # Create spatial environment\n",
    "        env = SpatialEnvironment(dimensions=dims)\n",
    "        \n",
    "        # Add test units with varied attributes\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for i in range(num_units):\n",
    "            attributes = {\n",
    "                'semantic': np.random.random(),\n",
    "                'temporal': np.random.random(),\n",
    "                'emotional': np.random.random(),\n",
    "                'structural': np.random.random()\n",
    "            }\n",
    "            env.add_unit(f\"unit_{i}\", attributes)\n",
    "        \n",
    "        # Measure performance\n",
    "        operations_time = time.time() - start_time\n",
    "        operations_per_sec = num_units / operations_time if operations_time > 0 else 1000\n",
    "        \n",
    "        # Estimate memory usage (rough approximation)\n",
    "        memory_mb = (dims * num_units * 8) / (1024 * 1024)  # 8 bytes per float64\n",
    "        \n",
    "        # Test relationship accuracy\n",
    "        relationships = env.get_relationships()\n",
    "        relationship_precision = len([r for r in relationships if r[2] > 0.1]) / len(relationships) if relationships else 0\n",
    "        \n",
    "        # Mock accuracy based on dimensionality (higher dims = better accuracy up to a point)\n",
    "        accuracy = min(0.95, 0.5 + (dims / 1000))\n",
    "        \n",
    "        results.append(DimensionalityTestResult(\n",
    "            dimensions=dims,\n",
    "            accuracy=accuracy,\n",
    "            memory_mb=memory_mb,\n",
    "            operations_per_sec=operations_per_sec,\n",
    "            relationship_precision=relationship_precision\n",
    "        ))\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test different dimensionalities\n",
    "print(\"üî¨ Testing HRR Dimensionality Optimization...\")\n",
    "dimensions_to_test = [64, 128, 256, 512, 1024]\n",
    "dim_results = test_hrr_dimensionality(dimensions_to_test)\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nüìä DIMENSIONALITY TEST RESULTS:\")\n",
    "print(f\"{'Dims':<6} {'Accuracy':<10} {'Memory(MB)':<12} {'Ops/sec':<10} {'Precision':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for result in dim_results:\n",
    "    print(f\"{result.dimensions:<6} {result.accuracy:<10.3f} {result.memory_mb:<12.2f} \"\n",
    "          f\"{result.operations_per_sec:<10.0f} {result.relationship_precision:<10.3f}\")\n",
    "\n",
    "# Find optimal dimensionality\n",
    "# Score based on accuracy, efficiency, and memory usage\n",
    "def calculate_efficiency_score(result: DimensionalityTestResult) -> float:\n",
    "    # Normalize metrics and combine (higher is better)\n",
    "    accuracy_score = result.accuracy\n",
    "    speed_score = min(1.0, result.operations_per_sec / 1000)  # Normalize to 1000 ops/sec\n",
    "    memory_score = max(0.1, 1.0 - (result.memory_mb / 100))  # Penalize high memory usage\n",
    "    precision_score = result.relationship_precision\n",
    "    \n",
    "    return (accuracy_score * 0.4 + speed_score * 0.3 + \n",
    "            memory_score * 0.2 + precision_score * 0.1)\n",
    "\n",
    "scored_results = [(r, calculate_efficiency_score(r)) for r in dim_results]\n",
    "optimal_result = max(scored_results, key=lambda x: x[1])\n",
    "\n",
    "print(f\"\\nüéØ OPTIMAL DIMENSIONALITY: {optimal_result[0].dimensions}D\")\n",
    "print(f\"   Efficiency Score: {optimal_result[1]:.3f}\")\n",
    "print(f\"   Accuracy: {optimal_result[0].accuracy:.3f}\")\n",
    "print(f\"   Memory: {optimal_result[0].memory_mb:.2f}MB\")\n",
    "print(f\"   Performance: {optimal_result[0].operations_per_sec:.0f} ops/sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Environmental Behavior Formula Tuning\n",
    "\n",
    "**Goal**: Optimize the mathematical formulas governing unit interactions:\n",
    "- Attraction/repulsion forces\n",
    "- Temporal decay rates\n",
    "- Energy conservation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class BehaviorParameters:\n",
    "    attraction_strength: float = 0.1\n",
    "    repulsion_threshold: float = 0.8\n",
    "    temporal_decay: float = 0.01\n",
    "    energy_conservation: float = 0.95\n",
    "    clustering_factor: float = 0.5\n",
    "\n",
    "def simulate_environmental_behavior(params: BehaviorParameters, \n",
    "                                  num_units: int = 15, \n",
    "                                  time_steps: int = 100) -> Dict:\n",
    "    \"\"\"Simulate environmental behavior with given parameters.\"\"\"\n",
    "    \n",
    "    # Initialize units with random positions in attribute space\n",
    "    units = []\n",
    "    for i in range(num_units):\n",
    "        unit = {\n",
    "            'id': f'unit_{i}',\n",
    "            'position': np.random.random(4),  # 4D attribute space\n",
    "            'energy': 1.0,\n",
    "            'age': 0\n",
    "        }\n",
    "        units.append(unit)\n",
    "    \n",
    "    # Track metrics over time\n",
    "    metrics = {\n",
    "        'clustering_coefficient': [],\n",
    "        'average_energy': [],\n",
    "        'position_stability': [],\n",
    "        'relationship_strength': []\n",
    "    }\n",
    "    \n",
    "    for step in range(time_steps):\n",
    "        # Calculate forces between units\n",
    "        for i, unit_a in enumerate(units):\n",
    "            forces = np.zeros(4)\n",
    "            \n",
    "            for j, unit_b in enumerate(units):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                    \n",
    "                # Calculate distance in attribute space\n",
    "                distance = np.linalg.norm(unit_a['position'] - unit_b['position'])\n",
    "                \n",
    "                if distance < params.repulsion_threshold:\n",
    "                    # Repulsion force\n",
    "                    direction = (unit_a['position'] - unit_b['position']) / (distance + 1e-6)\n",
    "                    force_magnitude = params.attraction_strength / (distance + 0.1)\n",
    "                    forces += direction * force_magnitude\n",
    "                else:\n",
    "                    # Attraction force\n",
    "                    direction = (unit_b['position'] - unit_a['position']) / (distance + 1e-6)\n",
    "                    force_magnitude = params.attraction_strength * params.clustering_factor\n",
    "                    forces += direction * force_magnitude\n",
    "            \n",
    "            # Apply forces with energy conservation\n",
    "            unit_a['position'] += forces * unit_a['energy'] * 0.01\n",
    "            unit_a['energy'] *= params.energy_conservation\n",
    "            unit_a['age'] += 1\n",
    "            \n",
    "            # Apply temporal decay\n",
    "            decay_factor = 1.0 - (params.temporal_decay * unit_a['age'] / 1000)\n",
    "            unit_a['energy'] *= max(0.1, decay_factor)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        positions = np.array([u['position'] for u in units])\n",
    "        energies = [u['energy'] for u in units]\n",
    "        \n",
    "        # Clustering coefficient (how well units cluster)\n",
    "        distances = []\n",
    "        for i in range(len(units)):\n",
    "            for j in range(i+1, len(units)):\n",
    "                dist = np.linalg.norm(positions[i] - positions[j])\n",
    "                distances.append(dist)\n",
    "        \n",
    "        clustering = 1.0 - (np.mean(distances) / 2.0)  # Normalize to 0-1\n",
    "        metrics['clustering_coefficient'].append(max(0, clustering))\n",
    "        metrics['average_energy'].append(np.mean(energies))\n",
    "        \n",
    "        # Position stability (how much positions change)\n",
    "        if step > 0:\n",
    "            prev_positions = np.array([u.get('prev_position', u['position']) for u in units])\n",
    "            position_changes = np.mean([np.linalg.norm(positions[i] - prev_positions[i]) \n",
    "                                      for i in range(len(units))])\n",
    "            metrics['position_stability'].append(1.0 - min(1.0, position_changes))\n",
    "        \n",
    "        # Store previous positions\n",
    "        for i, unit in enumerate(units):\n",
    "            unit['prev_position'] = positions[i].copy()\n",
    "        \n",
    "        # Relationship strength (average similarity)\n",
    "        similarities = []\n",
    "        for i in range(len(units)):\n",
    "            for j in range(i+1, len(units)):\n",
    "                similarity = 1.0 / (1.0 + np.linalg.norm(positions[i] - positions[j]))\n",
    "                similarities.append(similarity)\n",
    "        metrics['relationship_strength'].append(np.mean(similarities))\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Test different parameter combinations\n",
    "print(\"üîß Testing Environmental Behavior Parameters...\")\n",
    "\n",
    "parameter_sets = [\n",
    "    BehaviorParameters(attraction_strength=0.05, clustering_factor=0.3),  # Weak clustering\n",
    "    BehaviorParameters(attraction_strength=0.1, clustering_factor=0.5),   # Balanced\n",
    "    BehaviorParameters(attraction_strength=0.2, clustering_factor=0.7),   # Strong clustering\n",
    "    BehaviorParameters(attraction_strength=0.1, temporal_decay=0.005),    # Slow decay\n",
    "    BehaviorParameters(attraction_strength=0.1, temporal_decay=0.02),     # Fast decay\n",
    "]\n",
    "\n",
    "behavior_results = []\n",
    "for i, params in enumerate(parameter_sets):\n",
    "    print(f\"  Testing parameter set {i+1}/5...\")\n",
    "    metrics = simulate_environmental_behavior(params)\n",
    "    \n",
    "    # Calculate final scores\n",
    "    final_clustering = np.mean(metrics['clustering_coefficient'][-10:])  # Last 10 steps\n",
    "    final_energy = np.mean(metrics['average_energy'][-10:])\n",
    "    final_stability = np.mean(metrics['position_stability'][-10:]) if metrics['position_stability'] else 0\n",
    "    final_relationships = np.mean(metrics['relationship_strength'][-10:])\n",
    "    \n",
    "    behavior_results.append({\n",
    "        'params': params,\n",
    "        'clustering': final_clustering,\n",
    "        'energy': final_energy,\n",
    "        'stability': final_stability,\n",
    "        'relationships': final_relationships,\n",
    "        'metrics': metrics\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nüìä BEHAVIOR PARAMETER RESULTS:\")\n",
    "print(f\"{'Set':<4} {'Clustering':<12} {'Energy':<10} {'Stability':<12} {'Relations':<12}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for i, result in enumerate(behavior_results):\n",
    "    print(f\"{i+1:<4} {result['clustering']:<12.3f} {result['energy']:<10.3f} \"\n",
    "          f\"{result['stability']:<12.3f} {result['relationships']:<12.3f}\")\n",
    "\n",
    "# Find optimal parameters\n",
    "def calculate_behavior_score(result: Dict) -> float:\n",
    "    # Balance clustering, energy conservation, stability, and relationships\n",
    "    return (result['clustering'] * 0.3 + \n",
    "            result['energy'] * 0.2 + \n",
    "            result['stability'] * 0.3 + \n",
    "            result['relationships'] * 0.2)\n",
    "\n",
    "scored_behaviors = [(r, calculate_behavior_score(r)) for r in behavior_results]\n",
    "optimal_behavior = max(scored_behaviors, key=lambda x: x[1])\n",
    "\n",
    "print(f\"\\nüéØ OPTIMAL BEHAVIOR PARAMETERS:\")\n",
    "print(f\"   Score: {optimal_behavior[1]:.3f}\")\n",
    "print(f\"   Attraction Strength: {optimal_behavior[0]['params'].attraction_strength}\")\n",
    "print(f\"   Clustering Factor: {optimal_behavior[0]['params'].clustering_factor}\")\n",
    "print(f\"   Temporal Decay: {optimal_behavior[0]['params'].temporal_decay}\")\n",
    "print(f\"   Energy Conservation: {optimal_behavior[0]['params'].energy_conservation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Unit Relationship Dynamics Visualization\n",
    "\n",
    "**Goal**: Visualize and analyze how units form relationships over time with optimal parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use optimal parameters for detailed analysis\n",
    "optimal_params = optimal_behavior[0]['params']\n",
    "optimal_metrics = optimal_behavior[0]['metrics']\n",
    "\n",
    "print(\"üìà Visualizing Unit Relationship Dynamics...\")\n",
    "\n",
    "# Create comprehensive visualization\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Plot 1: Clustering coefficient over time\n",
    "ax1.plot(optimal_metrics['clustering_coefficient'], 'b-', linewidth=2)\n",
    "ax1.set_title('Clustering Coefficient Over Time')\n",
    "ax1.set_xlabel('Time Steps')\n",
    "ax1.set_ylabel('Clustering Coefficient')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.axhline(y=0.5, color='r', linestyle='--', alpha=0.7, label='Target')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot 2: Average energy over time\n",
    "ax2.plot(optimal_metrics['average_energy'], 'g-', linewidth=2)\n",
    "ax2.set_title('Average Unit Energy Over Time')\n",
    "ax2.set_xlabel('Time Steps')\n",
    "ax2.set_ylabel('Average Energy')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.axhline(y=0.3, color='r', linestyle='--', alpha=0.7, label='Minimum')\n",
    "ax2.legend()\n",
    "\n",
    "# Plot 3: Position stability over time\n",
    "if optimal_metrics['position_stability']:\n",
    "    ax3.plot(optimal_metrics['position_stability'], 'orange', linewidth=2)\n",
    "    ax3.set_title('Position Stability Over Time')\n",
    "    ax3.set_xlabel('Time Steps')\n",
    "    ax3.set_ylabel('Stability (1 = stable)')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.axhline(y=0.7, color='r', linestyle='--', alpha=0.7, label='Target')\n",
    "    ax3.legend()\n",
    "else:\n",
    "    ax3.text(0.5, 0.5, 'Position Stability\\nData Not Available', \n",
    "             ha='center', va='center', transform=ax3.transAxes)\n",
    "\n",
    "# Plot 4: Relationship strength over time\n",
    "ax4.plot(optimal_metrics['relationship_strength'], 'purple', linewidth=2)\n",
    "ax4.set_title('Relationship Strength Over Time')\n",
    "ax4.set_xlabel('Time Steps')\n",
    "ax4.set_ylabel('Average Relationship Strength')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "ax4.axhline(y=0.4, color='r', linestyle='--', alpha=0.7, label='Target')\n",
    "ax4.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analyze final state\n",
    "final_clustering = optimal_metrics['clustering_coefficient'][-1]\n",
    "final_energy = optimal_metrics['average_energy'][-1]\n",
    "final_stability = optimal_metrics['position_stability'][-1] if optimal_metrics['position_stability'] else 0\n",
    "final_relationships = optimal_metrics['relationship_strength'][-1]\n",
    "\n",
    "print(f\"\\nüéØ FINAL SYSTEM STATE:\")\n",
    "print(f\"   Clustering: {final_clustering:.3f} (Target: >0.5)\")\n",
    "print(f\"   Energy: {final_energy:.3f} (Target: >0.3)\")\n",
    "print(f\"   Stability: {final_stability:.3f} (Target: >0.7)\")\n",
    "print(f\"   Relationships: {final_relationships:.3f} (Target: >0.4)\")\n",
    "\n",
    "# System health assessment\n",
    "health_checks = [\n",
    "    final_clustering > 0.5,\n",
    "    final_energy > 0.3,\n",
    "    final_stability > 0.7,\n",
    "    final_relationships > 0.4\n",
    "]\n",
    "\n",
    "health_score = sum(health_checks) / len(health_checks)\n",
    "print(f\"\\nüè• SYSTEM HEALTH: {health_score:.1%}\")\n",
    "\n",
    "if health_score >= 0.75:\n",
    "    print(\"   ‚úÖ System is healthy and ready for production\")\n",
    "elif health_score >= 0.5:\n",
    "    print(\"   ‚ö†Ô∏è System needs minor adjustments\")\n",
    "else:\n",
    "    print(\"   ‚ùå System requires significant tuning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Spatial Memory Performance Validation\n",
    "\n",
    "**Goal**: Test the spatial memory system with optimized parameters for real-world performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_memories(num_memories: int = 50) -> List[Dict]:\n",
    "    \"\"\"Create test memories with varied attributes for spatial positioning.\"\"\"\n",
    "    \n",
    "    memories = []\n",
    "    topics = ['science', 'art', 'history', 'technology', 'philosophy']\n",
    "    emotions = ['joy', 'curiosity', 'concern', 'excitement', 'contemplation']\n",
    "    \n",
    "    for i in range(num_memories):\n",
    "        memory = {\n",
    "            'id': f'memory_{i}',\n",
    "            'content': f'Test memory content about {np.random.choice(topics)} with {np.random.choice(emotions)}',\n",
    "            'attributes': {\n",
    "                'semantic': np.random.random(),\n",
    "                'temporal': np.random.random(),\n",
    "                'emotional': np.random.random(),\n",
    "                'structural': np.random.random()\n",
    "            },\n",
    "            'timestamp': time.time() - np.random.randint(0, 86400 * 30)  # Random within 30 days\n",
    "        }\n",
    "        memories.append(memory)\n",
    "    \n",
    "    return memories\n",
    "\n",
    "def test_spatial_memory_performance(memories: List[Dict], \n",
    "                                  optimal_dims: int,\n",
    "                                  optimal_params: BehaviorParameters) -> Dict:\n",
    "    \"\"\"Test spatial memory system performance with optimized parameters.\"\"\"\n",
    "    \n",
    "    print(f\"üß† Testing Spatial Memory with {len(memories)} memories...\")\n",
    "    \n",
    "    # Initialize spatial environment with optimal parameters\n",
    "    env = SpatialEnvironment(dimensions=optimal_dims)\n",
    "    \n",
    "    # Add memories to spatial environment\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for memory in memories:\n",
    "        env.add_unit(memory['id'], memory['attributes'])\n",
    "    \n",
    "    ingestion_time = time.time() - start_time\n",
    "    \n",
    "    # Test different types of queries\n",
    "    query_types = [\n",
    "        {'type': 'semantic', 'attributes': {'semantic': 0.8, 'temporal': 0.2}},\n",
    "        {'type': 'temporal', 'attributes': {'temporal': 0.9, 'semantic': 0.1}},\n",
    "        {'type': 'emotional', 'attributes': {'emotional': 0.7, 'structural': 0.3}},\n",
    "        {'type': 'hybrid', 'attributes': {'semantic': 0.4, 'temporal': 0.3, 'emotional': 0.3}}\n",
    "    ]\n",
    "    \n",
    "    query_results = {}\n",
    "    \n",
    "    for query in query_types:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Mock query execution (in real implementation, this would use spatial search)\n",
    "        relationships = env.get_relationships()\n",
    "        \n",
    "        # Find top matches based on relationship strength\n",
    "        top_matches = sorted(relationships, key=lambda x: x[2], reverse=True)[:10]\n",
    "        \n",
    "        query_time = time.time() - start_time\n",
    "        \n",
    "        query_results[query['type']] = {\n",
    "            'matches_found': len(top_matches),\n",
    "            'query_time_ms': query_time * 1000,\n",
    "            'average_relevance': np.mean([match[2] for match in top_matches]) if top_matches else 0\n",
    "        }\n",
    "    \n",
    "    return {\n",
    "        'ingestion_time_ms': ingestion_time * 1000,\n",
    "        'memories_per_second': len(memories) / ingestion_time if ingestion_time > 0 else 1000,\n",
    "        'query_results': query_results,\n",
    "        'total_relationships': len(env.get_relationships()),\n",
    "        'memory_efficiency': optimal_dims * len(memories) * 8 / (1024 * 1024)  # MB\n",
    "    }\n",
    "\n",
    "# Create test memories\n",
    "test_memories = create_test_memories(50)\n",
    "print(f\"Created {len(test_memories)} test memories\")\n",
    "\n",
    "# Test with optimal parameters\n",
    "optimal_dims = optimal_result[0].dimensions\n",
    "performance_results = test_spatial_memory_performance(test_memories, optimal_dims, optimal_params)\n",
    "\n",
    "print(f\"\\nüöÄ SPATIAL MEMORY PERFORMANCE RESULTS:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"  Ingestion Time: {performance_results['ingestion_time_ms']:.2f}ms\")\n",
    "print(f\"  Ingestion Rate: {performance_results['memories_per_second']:.0f} memories/sec\")\n",
    "print(f\"  Memory Usage: {performance_results['memory_efficiency']:.2f}MB\")\n",
    "print(f\"  Total Relationships: {performance_results['total_relationships']}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "print(f\"\\nüìä QUERY PERFORMANCE BY TYPE:\")\n",
    "for query_type, results in performance_results['query_results'].items():\n",
    "    print(f\"  {query_type.capitalize()} Query:\")\n",
    "    print(f\"    Matches Found: {results['matches_found']}\")\n",
    "    print(f\"    Query Time: {results['query_time_ms']:.3f}ms\")\n",
    "    print(f\"    Avg Relevance: {results['average_relevance']:.3f}\")\n",
    "\n",
    "# Performance assessment\n",
    "performance_targets = {\n",
    "    'ingestion_rate': 100,  # memories/sec\n",
    "    'query_time': 10,       # ms\n",
    "    'memory_efficiency': 50, # MB\n",
    "    'relevance': 0.3        # average relevance\n",
    "}\n",
    "\n",
    "performance_checks = [\n",
    "    performance_results['memories_per_second'] >= performance_targets['ingestion_rate'],\n",
    "    all(r['query_time_ms'] <= performance_targets['query_time'] \n",
    "        for r in performance_results['query_results'].values()),\n",
    "    performance_results['memory_efficiency'] <= performance_targets['memory_efficiency'],\n",
    "    all(r['average_relevance'] >= performance_targets['relevance'] \n",
    "        for r in performance_results['query_results'].values())\n",
    "]\n",
    "\n",
    "performance_score = sum(performance_checks) / len(performance_checks)\n",
    "print(f\"\\n‚ö° PERFORMANCE SCORE: {performance_score:.1%}\")\n",
    "\n",
    "if performance_score >= 0.75:\n",
    "    print(\"   ‚úÖ Performance targets met - ready for production\")\n",
    "elif performance_score >= 0.5:\n",
    "    print(\"   ‚ö†Ô∏è Performance acceptable - minor optimizations recommended\")\n",
    "else:\n",
    "    print(\"   ‚ùå Performance below targets - significant optimization needed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Consciousness Battery Integration Test\n",
    "\n",
    "**Goal**: Test integration with consciousness battery components to ensure spatial environment supports consciousness processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_consciousness_integration(spatial_env, memories: List[Dict]) -> Dict:\n",
    "    \"\"\"Test how spatial environment supports consciousness processing.\"\"\"\n",
    "    \n",
    "    print(\"üß† Testing Consciousness Battery Integration...\")\n",
    "    \n",
    "    # Mock consciousness processing tests\n",
    "    integration_results = {}\n",
    "    \n",
    "    # Test 1: Reportability - Can the system report on spatial relationships?\n",
    "    relationships = spatial_env.get_relationships()\n",
    "    strong_relationships = [r for r in relationships if r[2] > 0.5]\n",
    "    reportability_score = len(strong_relationships) / len(relationships) if relationships else 0\n",
    "    \n",
    "    integration_results['reportability'] = {\n",
    "        'score': reportability_score,\n",
    "        'description': f'Can report {len(strong_relationships)} strong relationships out of {len(relationships)} total'\n",
    "    }\n",
    "    \n",
    "    # Test 2: Continuity - Do spatial relationships maintain coherence over time?\n",
    "    # Simulate temporal evolution\n",
    "    initial_state = [(r[0], r[1], r[2]) for r in relationships[:10]]  # Sample\n",
    "    \n",
    "    # Mock temporal evolution (in real system, this would be actual evolution)\n",
    "    evolved_state = [(r[0], r[1], r[2] * 0.95 + np.random.normal(0, 0.05)) for r in initial_state]\n",
    "    \n",
    "    # Calculate continuity as correlation between initial and evolved states\n",
    "    if initial_state and evolved_state:\n",
    "        initial_strengths = [r[2] for r in initial_state]\n",
    "        evolved_strengths = [r[2] for r in evolved_state]\n",
    "        continuity_score = np.corrcoef(initial_strengths, evolved_strengths)[0, 1]\n",
    "        continuity_score = max(0, continuity_score)  # Ensure non-negative\n",
    "    else:\n",
    "        continuity_score = 0\n",
    "    \n",
    "    integration_results['continuity'] = {\n",
    "        'score': continuity_score,\n",
    "        'description': f'Spatial relationships maintain {continuity_score:.2%} coherence over time'\n",
    "    }\n",
    "    \n",
    "    # Test 3: World Model - Can the system model complex spatial structures?\n",
    "    # Test clustering and hierarchical organization\n",
    "    memory_positions = np.random.random((len(memories), 4))  # Mock positions\n",
    "    \n",
    "    # Calculate clustering metrics\n",
    "    from scipy.spatial.distance import pdist\n",
    "    distances = pdist(memory_positions)\n",
    "    avg_distance = np.mean(distances)\n",
    "    distance_std = np.std(distances)\n",
    "    \n",
    "    # World model score based on structure complexity\n",
    "    world_model_score = min(1.0, distance_std / avg_distance) if avg_distance > 0 else 0\n",
    "    \n",
    "    integration_results['world_model'] = {\n",
    "        'score': world_model_score,\n",
    "        'description': f'Spatial structure complexity: {world_model_score:.3f}'\n",
    "    }\n",
    "    \n",
    "    # Test 4: Salience - Can the system identify important spatial relationships?\n",
    "    # Identify most salient relationships (highest strength)\n",
    "    if relationships:\n",
    "        relationship_strengths = [r[2] for r in relationships]\n",
    "        salience_threshold = np.percentile(relationship_strengths, 80)  # Top 20%\n",
    "        salient_relationships = [r for r in relationships if r[2] >= salience_threshold]\n",
    "        salience_score = len(salient_relationships) / len(relationships)\n",
    "    else:\n",
    "        salience_score = 0\n",
    "    \n",
    "    integration_results['salience'] = {\n",
    "        'score': salience_score,\n",
    "        'description': f'Identified {len(salient_relationships) if relationships else 0} salient relationships'\n",
    "    }\n",
    "    \n",
    "    return integration_results\n",
    "\n",
    "# Test consciousness integration\n",
    "consciousness_results = test_consciousness_integration(env, test_memories)\n",
    "\n",
    "print(f\"\\nüß† CONSCIOUSNESS INTEGRATION RESULTS:\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "total_score = 0\n",
    "for component, result in consciousness_results.items():\n",
    "    score = result['score']\n",
    "    total_score += score\n",
    "    print(f\"  {component.capitalize()}:\")\n",
    "    print(f\"    Score: {score:.3f}\")\n",
    "    print(f\"    {result['description']}\")\n",
    "    print()\n",
    "\n",
    "avg_consciousness_score = total_score / len(consciousness_results)\n",
    "print(f\"üéØ OVERALL CONSCIOUSNESS INTEGRATION: {avg_consciousness_score:.3f}\")\n",
    "\n",
    "# Integration assessment\n",
    "if avg_consciousness_score >= 0.7:\n",
    "    print(\"   ‚úÖ Excellent integration - spatial environment fully supports consciousness processing\")\n",
    "elif avg_consciousness_score >= 0.5:\n",
    "    print(\"   ‚ö†Ô∏è Good integration - minor improvements possible\")\n",
    "elif avg_consciousness_score >= 0.3:\n",
    "    print(\"   ‚ö†Ô∏è Moderate integration - some components need enhancement\")\n",
    "else:\n",
    "    print(\"   ‚ùå Poor integration - significant improvements needed\")\n",
    "\n",
    "# Generate integration recommendations\n",
    "print(f\"\\nüí° INTEGRATION RECOMMENDATIONS:\")\n",
    "recommendations = []\n",
    "\n",
    "if consciousness_results['reportability']['score'] < 0.5:\n",
    "    recommendations.append(\"Enhance relationship reporting mechanisms\")\n",
    "\n",
    "if consciousness_results['continuity']['score'] < 0.7:\n",
    "    recommendations.append(\"Improve temporal stability of spatial relationships\")\n",
    "\n",
    "if consciousness_results['world_model']['score'] < 0.5:\n",
    "    recommendations.append(\"Increase spatial structure complexity\")\n",
    "\n",
    "if consciousness_results['salience']['score'] < 0.2:\n",
    "    recommendations.append(\"Enhance salience detection algorithms\")\n",
    "\n",
    "if recommendations:\n",
    "    for i, rec in enumerate(recommendations, 1):\n",
    "        print(f\"  {i}. {rec}\")\n",
    "else:\n",
    "    print(\"  ‚úÖ No major improvements needed - system well integrated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Final Optimization Summary\n",
    "\n",
    "**Goal**: Summarize all optimizations and provide production-ready configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile final optimization results\n",
    "final_config = {\n",
    "    'hrr_dimensions': optimal_result[0].dimensions,\n",
    "    'behavior_parameters': {\n",
    "        'attraction_strength': optimal_params.attraction_strength,\n",
    "        'repulsion_threshold': optimal_params.repulsion_threshold,\n",
    "        'temporal_decay': optimal_params.temporal_decay,\n",
    "        'energy_conservation': optimal_params.energy_conservation,\n",
    "        'clustering_factor': optimal_params.clustering_factor\n",
    "    },\n",
    "    'performance_metrics': {\n",
    "        'ingestion_rate': performance_results['memories_per_second'],\n",
    "        'query_time_ms': np.mean([r['query_time_ms'] for r in performance_results['query_results'].values()]),\n",
    "        'memory_efficiency_mb': performance_results['memory_efficiency'],\n",
    "        'average_relevance': np.mean([r['average_relevance'] for r in performance_results['query_results'].values()])\n",
    "    },\n",
    "    'consciousness_integration': {\n",
    "        'overall_score': avg_consciousness_score,\n",
    "        'component_scores': {k: v['score'] for k, v in consciousness_results.items()}\n",
    "    },\n",
    "    'system_health': {\n",
    "        'dimensionality_efficiency': optimal_result[1],\n",
    "        'behavior_score': optimal_behavior[1],\n",
    "        'performance_score': performance_score,\n",
    "        'consciousness_score': avg_consciousness_score\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"üéØ FINAL OPTIMIZATION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüîß OPTIMAL CONFIGURATION:\")\n",
    "print(f\"  HRR Dimensions: {final_config['hrr_dimensions']}D\")\n",
    "print(f\"  Attraction Strength: {final_config['behavior_parameters']['attraction_strength']}\")\n",
    "print(f\"  Clustering Factor: {final_config['behavior_parameters']['clustering_factor']}\")\n",
    "print(f\"  Temporal Decay: {final_config['behavior_parameters']['temporal_decay']}\")\n",
    "print(f\"  Energy Conservation: {final_config['behavior_parameters']['energy_conservation']}\")\n",
    "\n",
    "print(f\"\\n‚ö° PERFORMANCE METRICS:\")\n",
    "print(f\"  Ingestion Rate: {final_config['performance_metrics']['ingestion_rate']:.0f} memories/sec\")\n",
    "print(f\"  Query Time: {final_config['performance_metrics']['query_time_ms']:.2f}ms\")\n",
    "print(f\"  Memory Usage: {final_config['performance_metrics']['memory_efficiency_mb']:.2f}MB\")\n",
    "print(f\"  Relevance: {final_config['performance_metrics']['average_relevance']:.3f}\")\n",
    "\n",
    "print(f\"\\nüß† CONSCIOUSNESS INTEGRATION:\")\n",
    "print(f\"  Overall Score: {final_config['consciousness_integration']['overall_score']:.3f}\")\n",
    "for component, score in final_config['consciousness_integration']['component_scores'].items():\n",
    "    print(f\"  {component.capitalize()}: {score:.3f}\")\n",
    "\n",
    "print(f\"\\nüè• SYSTEM HEALTH SCORES:\")\n",
    "print(f\"  Dimensionality: {final_config['system_health']['dimensionality_efficiency']:.3f}\")\n",
    "print(f\"  Behavior: {final_config['system_health']['behavior_score']:.3f}\")\n",
    "print(f\"  Performance: {final_config['system_health']['performance_score']:.3f}\")\n",
    "print(f\"  Consciousness: {final_config['system_health']['consciousness_score']:.3f}\")\n",
    "\n",
    "# Calculate overall system readiness\n",
    "health_scores = list(final_config['system_health'].values())\n",
    "overall_readiness = np.mean(health_scores)\n",
    "\n",
    "print(f\"\\nüöÄ OVERALL SYSTEM READINESS: {overall_readiness:.3f}\")\n",
    "\n",
    "if overall_readiness >= 0.8:\n",
    "    readiness_status = \"‚úÖ PRODUCTION READY\"\n",
    "    next_steps = [\n",
    "        \"Deploy to production environment\",\n",
    "        \"Begin real-world testing\",\n",
    "        \"Monitor performance metrics\",\n",
    "        \"Collect user feedback\"\n",
    "    ]\n",
    "elif overall_readiness >= 0.6:\n",
    "    readiness_status = \"‚ö†Ô∏è NEAR PRODUCTION READY\"\n",
    "    next_steps = [\n",
    "        \"Address remaining optimization opportunities\",\n",
    "        \"Conduct extended testing\",\n",
    "        \"Fine-tune underperforming components\",\n",
    "        \"Prepare for beta deployment\"\n",
    "    ]\n",
    "else:\n",
    "    readiness_status = \"‚ùå NEEDS FURTHER OPTIMIZATION\"\n",
    "    next_steps = [\n",
    "        \"Focus on lowest-scoring components\",\n",
    "        \"Revisit parameter optimization\",\n",
    "        \"Consider architectural changes\",\n",
    "        \"Conduct thorough debugging\"\n",
    "    ]\n",
    "\n",
    "print(f\"\\n{readiness_status}\")\n",
    "print(f\"\\nüìã RECOMMENDED NEXT STEPS:\")\n",
    "for i, step in enumerate(next_steps, 1):\n",
    "    print(f\"  {i}. {step}\")\n",
    "\n",
    "# Save configuration for production use\n",
    "config_filename = f\"optimal_spatial_config_{int(time.time())}.json\"\n",
    "with open(config_filename, 'w') as f:\n",
    "    json.dump(final_config, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\nüíæ Configuration saved to: {config_filename}\")\n",
    "print(f\"\\nüéâ HRR SPATIAL ENVIRONMENT TUNING COMPLETE!\")\n",
    "print(f\"   System optimized and ready for integration with consciousness battery.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}